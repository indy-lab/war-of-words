{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# War of Words - Model Evaluation\n",
    "\n",
    "Use this notebook to train and evaluate the War of Words models:\n",
    "- With MEPs only (`WoW`)\n",
    "- With rapporteur advantage (`WoW(R)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from warofwords import WarOfWords, TrainedWarOfWords\n",
    "\n",
    "# Define all experiments.\n",
    "experiments = [{\n",
    "    'leg': 7,           # Legislature.\n",
    "    'reg': 0.32,        # Hyperparameters.\n",
    "    'mtype': 'meponly'  # Model types.\n",
    "}, {\n",
    "    'leg': 7,\n",
    "    'reg': 0.39,\n",
    "    'mtype': 'rapadv'\n",
    "},{\n",
    "    'leg': 8,\n",
    "    'reg': 0.35,\n",
    "    'mtype': 'meponly'\n",
    "},{\n",
    "    'leg': 8,\n",
    "    'reg': 0.39,\n",
    "    'mtype': 'rapadv'\n",
    "}]\n",
    "\n",
    "\n",
    "def evaluate(modeltype, leg, regularizer):\n",
    "    \"\"\"Evaluate a model on a given legislature.\"\"\"\n",
    "    print(f'Evaluating \"{modeltype}\" on EP{leg}')\n",
    "    # Load data.\n",
    "    path = f'../data/processed/{modeltype}-ep{leg}-train.pkl'\n",
    "    features, featmats, labels = WarOfWords.load_data(path)\n",
    "    train = list(zip(featmats, labels))\n",
    "    \n",
    "    # Initialize model.\n",
    "    hyperparams = WarOfWords.Hyperparameters(regularizer=regularizer)\n",
    "    model = WarOfWords(train, features, hyperparams, bias_key='bias')\n",
    "    \n",
    "    # Train model.\n",
    "    print('  Training...')\n",
    "    params, cost = model.fit()\n",
    "    llh = model.log_likelihood(params['params'].as_array())\n",
    "    print(f'  Log-likelihood: {llh:.2f}')\n",
    "          \n",
    "    # Initialize trained model.\n",
    "    trained = TrainedWarOfWords(features, hyperparams, **params)\n",
    "    \n",
    "    # Load test set.\n",
    "    path = f'../data/processed/{modeltype}-ep{leg}-test.pkl'\n",
    "    features, featmats, labels = TrainedWarOfWords.load_data(path)\n",
    "    test = list(zip(featmats, labels))\n",
    "    \n",
    "    # Evaluate log loss.\n",
    "    print(f'  Log-loss on test set: {trained.log_loss(test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating \"meponly\" on EP7\n",
      "  Training...\n",
      "  Log-likelihood: -61034.69\n",
      "  Log-loss on test set: 0.714\n",
      "Evaluating \"rapadv\" on EP7\n",
      "  Training...\n",
      "  Log-likelihood: -58885.19\n",
      "  Log-loss on test set: 0.690\n",
      "Evaluating \"meponly\" on EP8\n",
      "  Training...\n",
      "  Log-likelihood: -71970.44\n",
      "  Log-loss on test set: 0.748\n",
      "Evaluating \"rapadv\" on EP8\n",
      "  Training...\n",
      "  Log-likelihood: -69568.96\n",
      "  Log-loss on test set: 0.726\n",
      "CPU times: user 13min 14s, sys: 12.7 s, total: 13min 27s\n",
      "Wall time: 14min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for exp in experiments:\n",
    "    evaluate(exp['mtype'], exp['leg'], exp['reg'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
